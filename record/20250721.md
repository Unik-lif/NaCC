## 实验记录
先前打算给agent区域单拿出来一个entry来使用，为此可能还要放到kernel part

但是或许更好的方式是直接将其放到user part，只不过最后一项页表项中，我添加上U bit

考虑到我们放置agent区域的虚拟地址和物理地址都是连续的，我们可以通过大页的方式来加快访问速度，减少TLB Miss出现的次数

此外，由于正好放到user part区域，我们就不需要在硬件上额外设置一个利用nacc_state做判别的防护机制了，直接对前256 entry这一区域做好防护就可以了

首先我们需要在go语言这边利用syscall来做mmap，分配了一块儿较大的虚拟地址空间，这一步已经实现了

之后的一个大问题是agent的初始化

我们的路径可能是这样
```shell

[runc]     init
    |       ^
    v       |
[Linux] nacc_invoke    [Agent] entry -> [Agent] ecall
    |       ^                 ^             |
    v       |                 |             v
====================================================
|  [sm]         sm_register_cid                    |
====================================================

```

有一些同步的信息困扰了我一阵，但是我想清楚了，本质上还是要维持一些context上下文信息给opensbi来用，似乎理解了为什么kvm核kvmtool这一类工作会去存放一个上下文，确实非常棘手，如果可以的话，其实最好还是得把模型转化成stateless状态


我们先把大页给他做了，同时把有paddr和vaddr的函数一并给他在同一个函数中实现

大页的原理在rCore中写的不错的

> RISC-V 64处理器在地址转换过程中，只要表项中的 V 为 1 且 R/W/X 不全为 0 就会直接从当前的页表项中取出物理页号，再接上页内偏移，就完成最终的地址转换。注意这个过程可以发生在多级页表的任意一级。如果这一过程并没有发生在多级页表的最深层，那么在地址转换的时候，物理页号对应的物理页帧的起始物理地址的位数与页内偏移的位数都和按缺省页处理时的情况不同了。我们需要按 大页 的地址转换方式来处理。

也就是原本的vpn[0..1]等bit区域，现在我们直接把他和后面的offset放在一起来做索引，这样确实可以提升访存的效率

把hugepage页表映射给他加上了，不难写，看起来跑起来没什么大问题

确认hugepage是否映射成功了，还需要真的跳转到agent区域做初始化，尝试搞清楚跳转到agent的一些基本操作，读一下别人的实现
