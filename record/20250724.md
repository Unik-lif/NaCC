## 实验记录
从昨天的实验结果来看，很有可能我们映射的时候出错了

虽然物理地址上的访问似乎是正确的，但是虚拟地址似乎没有映射到比较合适的位置

我们可能还是得更加谨慎点看看

qemu似乎展示的info mem信息，并不是我们当前正在运行的active hart所展示的信息，我看到了一些非常诡异的现象
```
(qemu) x /4x 0x3f00000000
0000003f00000000: 0x00002697 0x00068693 0x00100613 0x00c6a6af
(qemu) xp /4x 0x180000000
0000000180000000: 0x00002697 0x00068693 0x00100613 0x00c6a6af
```

很奇怪，有时候好像我们的映射就是可以成功，但是有时候不可以。

这个会不会是受到了mmap本身行为的影响？

也许是多核引入的变量也说不准

也许linux本身的中断处理器就有点小问题，不能及时地去看到底是谁产生的错误？从而导致我们这边实际上跑到的pc是不好讲的？
```
[SBI] want to jump to the agent region at 3f18000000
[  303.288515] Insufficient stack space to handle exception!
[  303.289023] Task stack:     [0xffffffc6013d8000..0xffffffc6013dc000]
[  303.289519] Overflow stack: [0xffffffd6fefaa070..0xffffffd6fefab070]
[  303.290553] CPU: 1 UID: 0 PID: 980 Comm: runc:[2:INIT] Not tainted 6.12.0-00004-g586e0b81b173-dirty #1
[  303.291629] Hardware name: riscv-virtio,qemu (DT)
[  303.292280] epc : 0x3f18000000
[  303.293409]  ra : 0x80013280
[  303.293716] epc : 0000003f18000000 ra : 0000000080013280 sp : 000000008004dda0
[  303.294203]  gp : ffffffff81718d30 tp : 0000000000000000 t0 : 0000000000000000
[  303.294697]  t1 : 0000000000000002 t2 : 0000000000000000 s0 : 000000008004ddf0
[  303.295336]  s1 : 0000000180000400 a0 : 0000000000000035 a1 : 000000000000000a
[  303.295841]  a2 : 0000000000000001 a3 : ffffffffffffe77f a4 : 0000000000000800
[  303.296367]  a5 : 0000000a00000822 a6 : 0000000000000005 a7 : 0000000080045e90
[  303.296918]  s2 : 0000000180000410 s3 : 0000000180000400 s4 : 0000000180000410
[  303.297417]  s5 : 0000003f18000000 s6 : 0000000000000004 s7 : 0000000000001000
[  303.297918]  s8 : 0000003d98000000 s9 : 0000003ff3d4e0d0 s10: 0000003f5402b6f0
[  303.298398]  s11: 0000003f540001c0 t3 : 000000008004dc65 t4 : 0000000000000003
[  303.298940]  t5 : 0000000000000009 t6 : 0000000000000061
[  303.299446] status: 0000000200000120 badaddr: 0000000000000000 cause: 8000000000000001
[  303.300534] Kernel panic - not syncing: Kernel stack overflow
[  303.301498] CPU: 1 UID: 0 PID: 980 Comm: runc:[2:INIT] Not tainted 6.12.0-00004-g586e0b81b173-dirty #1
[  303.302085] Hardware name: riscv-virtio,qemu (DT)
[  303.302451] Call Trace:
[  303.303058] [<ffffffff800065f0>] dump_backtrace+0x1c/0x24
[  303.304384] [<ffffffff80a1b400>] show_stack+0x2e/0x38
[  303.304746] [<ffffffff80a2823e>] dump_stack_lvl+0x52/0x74
[  303.305096] [<ffffffff80a28274>] dump_stack+0x14/0x1c
[  303.305427] [<ffffffff80a1b982>] panic+0x10e/0x302
[  303.305750] [<ffffffff80006492>] save_wchan+0x0/0x34
[  303.306579] SMP: stopping secondary CPUs
[  303.308857] ---[ end Kernel panic - not syncing: Kernel stack overflow ]---
```
发现是qemu需要切换cpu才能看到我们想要的值，算是破案了，但是现在的异常处理入口还是非常奇怪，我们想办法缓解这个问题

看到了确实似乎进入到了agent中，但是由于寄存器的值有点不怎么对，造成了一些异常情况，比如很奇怪，异常最后处理又跑到了linux中去了，我们得尝试把中断给关掉

现在我们可能得尝试为agent构造上下文信息，仿照opensbi给linux的状态，来尝试做这件事情

```
还没设置SIE bit，在mret前的mstatus值
(gdb) p/t $mstatus                                                                                                                                                                            
$4 = 101000000000000000000000100000100010

设置了SIE bit为0，在mret前的mstatus值
(gdb) p /t $mstatus           
$1 = 101000000000000000000000100000  1   000   0   0
                                    SPIE      SIE
                                       
设置了SIE bit为0，在mret后的mstatus值
(gdb) p /t $mstatus                                                                                                                                                                           
$1 = 101000000000000000000000000     1     1  0   0   000   1   0
                                    SPP   MPIE   SPIE      SIE

```

有可能是在状态变化的时候，从SPIE中重新读了值，导致现在的SIE还是有值，那如果是这样的

好家伙，我直接好家伙，riscv的手册写的真的太简单了，对于搞OS的人确实不是特别友好。手册里说xRET就动xPIE和xIE，但是看起来MRET动了以后，连SPIE和SIE都有变化了

有意思，我再试试看


似乎还是不行，变动还是比较大，感觉是路径上出了一些问题，要不我们先把midelegate等东西关掉？确保这个中断只能由Opensbi来处理？不要让他进入到S mode的Linux中断处理者头上？

```
Thread 4 hit Breakpoint 1, sm_register_cid (cid=cid@entry=979757352371, agent_virt_start=agent_virt_start@entry=270918483968) at /home/link/Desktop/NaCC/opensbi/lib/sbi/sm/sm.c:116
116         __asm__ __volatile("mret");
(gdb) p /t $mstatus
$1 = 101000000000000000000000100000000010
(gdb) n
^C
Thread 4 received signal SIGINT, Interrupt.
0xffffffff80a1a77e in ?? ()
(gdb) p /t $mstatus
$2 = 101000000000000000000000000110100010
```

最后选择关闭了页表，毕竟agent需要初始化。

然后确实进入进去了，但是卡在了test_main这个位置上，原因我不大清楚

目前的agent还是按照多核写的，但是不应该这样做，应该就只是单核serving就行，它并非一个真正的mini-OS

还需要花一些时间确认一下相关的细节，但是相比昨天确实已经有较大的进展了。

我们现在的目标是在agent这边能够看到agent的输出，不过确实很奇妙，为什么test_main这一环节就卡住了呢？