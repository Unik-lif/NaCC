## 实验记录
我们看到hello world所对应的被迁移后的地址空间如下所示
```
..0: pte 6ffff801 pa 1bfffe000 [level 2]
.. ..0: pte 6ffff401 pa 1bfffd000 [level 1]
..255: pte 6ffff001 pa 1bfffc000 [level 2]
.. ..111: pte 6fffec01 pa 1bfffb000 [level 1]
```
对于下面的这个虚拟地址，0x10160，应该走的是0，0，0x10这条PTE，这个行为不成功的原因是涉及了level 1，即PMD的修改，而这个修改在我们的环节中是不被允许的

那为什么是没有异常呢？我得搞清楚这件事情！

观察到异常现象
```
Breakpoint 2, do_read_fault (vmf=0xffffffc6006e3928) at /home/link/NaCC/linux/mm/memory.c:5352
5352            if (should_fault_around(vmf)) {
(gdb) n
5353                    ret = do_fault_around(vmf);
(gdb) n
5354                    if (ret)
(gdb) p/x ret
$1 = 0x100
(gdb) 
```
不知道为什么这边的ret的值是0x100，搞清楚它

现象：处理的时候似乎软硬件没有对齐，pmd指向的pte似乎没有被得到操作，linux向下遍历的时候竟然去操作了一个孤立的页！这个页不仅没有和之前的页表页链接上，而且还不是机密内存

应该是攫取pte的时候有点问题，并没有按照常规方式来，找到了关键函数位置
```C
vm_fault_t filemap_map_pages(struct vm_fault *vmf,
			     pgoff_t start_pgoff, pgoff_t end_pgoff)
{
	struct vm_area_struct *vma = vmf->vma;
	struct file *file = vma->vm_file;
	struct address_space *mapping = file->f_mapping;
	pgoff_t file_end, last_pgoff = start_pgoff;
	unsigned long addr;
	XA_STATE(xas, &mapping->i_pages, start_pgoff);
	struct folio *folio;
	vm_fault_t ret = 0;
	unsigned long rss = 0;
	unsigned int nr_pages = 0, mmap_miss = 0, mmap_miss_saved, folio_type;

	rcu_read_lock();
	folio = next_uptodate_folio(&xas, mapping, end_pgoff);
	if (!folio)
		goto out;

	if (filemap_map_pmd(vmf, folio, start_pgoff)) {
		ret = VM_FAULT_NOPAGE;
		goto out;
	}

	addr = vma->vm_start + ((start_pgoff - vma->vm_pgoff) << PAGE_SHIFT);
	vmf->pte = pte_offset_map_lock(vma->vm_mm, vmf->pmd, addr, &vmf->ptl);
	if (!vmf->pte) {
		folio_unlock(folio);
		folio_put(folio);
		goto out;
	}

	file_end = DIV_ROUND_UP(i_size_read(mapping->host), PAGE_SIZE) - 1;
	if (end_pgoff > file_end)
		end_pgoff = file_end;

	folio_type = mm_counter_file(folio);
	do {
		unsigned long end;

		addr += (xas.xa_index - last_pgoff) << PAGE_SHIFT;
		vmf->pte += xas.xa_index - last_pgoff;
		last_pgoff = xas.xa_index;
		end = folio_next_index(folio) - 1;
		nr_pages = min(end, end_pgoff) - xas.xa_index + 1;

		if (!folio_test_large(folio))
			ret |= filemap_map_order0_folio(vmf,
					folio, addr, &rss, &mmap_miss);
		else
			ret |= filemap_map_folio_range(vmf, folio,
					xas.xa_index - folio->index, addr,
					nr_pages, &rss, &mmap_miss);

		folio_unlock(folio);
		folio_put(folio);
	} while ((folio = next_uptodate_folio(&xas, mapping, end_pgoff)) != NULL);
	add_mm_counter(vma->vm_mm, folio_type, rss);
	pte_unmap_unlock(vmf->pte, vmf->ptl);
	trace_mm_filemap_map_pages(mapping, start_pgoff, end_pgoff);
out:
	rcu_read_unlock();

	mmap_miss_saved = READ_ONCE(file->f_ra.mmap_miss);
	if (mmap_miss >= mmap_miss_saved)
		WRITE_ONCE(file->f_ra.mmap_miss, 0);
	else
		WRITE_ONCE(file->f_ra.mmap_miss, mmap_miss_saved - mmap_miss);

	return ret;
}
```
观测到是在pte_offset_map_lock中并没有找到正确的值，这个是我们先前解决销毁问题的历史包袱
- 在销毁问题中，由于linux本身没有办法对机密内存做销毁，因此我们其实收集的是被替换前的页表页，然后对于替换后的机密内存页表页，则是通过opensbi的接口来进行回收
- 这对应了在做__pte_offset_map_lock时的状态修改，函数最后会返回原本对应的pte作为结果

但是在处理page fault的时候，因为再次涉及了页表，我们同样使用了__pte_offset_map_lock函数
- 我们期望得到的恰好是正常去访问一个pmd或者pte所带来的结果
- 可能新添加的页表页甚至也不会有旧的页表页与之对应

正常与不正常
- 归约一下我们可以发现，似乎只有在需要做销毁的时候，我们才真正需要去做特殊处理，去找到对应的mappings
- 其他情况下都还是维持正常的

linux如何知晓自己需要销毁
- 包括execve等系统调用的语义中含有销毁，因此可以在nacc_flag中添加上对应的语义信息